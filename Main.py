import os
import pickle
import matplotlib.pyplot as plt
import neat
import tensorflow as tf
from Autoencoder import auto_encoder_3d, create_auto_encoder
from Delenox_Config import *

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

if __name__ == '__main__':

    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
    physical_devices = tf.config.experimental.list_physical_devices('GPU')
    assert len(physical_devices) > 0, "Not enough GPU hardware devices available"
    tf.config.experimental.set_memory_growth(physical_devices[0], True)

    # Load configuration file according to the given path and setting relevant parameters.
    local_dir = os.path.dirname(__file__)
    config_path = os.path.join(local_dir, 'neat.cfg')
    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, neat.DefaultSpeciesSet,
                         neat.DefaultStagnation, config_path)
    config.genome_config.add_activation('sin_adjusted', sinc)

    # Lists for the training population of an iteration, and the history of all training populations
    training_history = []
    training_population = []

    # Flag to test a static configuration of DeLeNoX, where no transformation phases take place
    static = False

    # Loop through the phase numbers provided, if the list starts from a value greater than zero, it resumes the experiment from the given phase
    for phase in range(number_of_phases):

        # If this is the first iteration of DeLeNoX, use the NEAT population seeds provided
        if phase == 0:
            neat_generators = [pickle.load(open("Delenox_Experiment_Data/Seed/Neat_Population_{:d}".format(runs),
                                                "rb")) for runs in range(runs_per_phase)]
        else:
            # Otherwise, load up the populations generated by the previous phase
            neat_generators = [pickle.load(open("Delenox_Experiment_Data/Phase{:d}/Neat_Population_{:d}".format(phase-1, runs),
                                                "rb")) for runs in range(runs_per_phase)]

        # Execute the exploration phase and get the resulting population of novel individuals and statistics.
        neat_metrics = {'Mean Novelty': [],
                        'Best Novelty': [],
                        'Node Complexity': [],
                        'Connection Complexity': [],
                        'Archive Size': [],
                        'Species Count': [],
                        }

        for number in range(len(neat_generators)):

            # Run the NEAT phase and update the generator and novel population accordingly
            (generator, best_fit, metrics) = neat_generators[number].run_neat(phase, static)
            training_population += list(best_fit)

            # Save the neat populations to pickle files in the current phase folder
            with open("./Delenox_Experiment_Data/Phase{:d}/Neat_Population_{:d}".format(phase, number), "wb+") as f:
                pickle.dump(generator, f)

            # Update the metrics dictionary with this phase' results
            for key in metrics.keys():
                neat_metrics[key].append(metrics[key])

        # Save the metrics to a numpy file for later extraction
        np.save("./Delenox_Experiment_Data/Phase{:d}/Metrics.npy".format(phase), neat_metrics)

        # Update the training history with the novel population of this phase
        training_history += list(training_population)

        # Create a new auto-encoder with the data generated from this iteration's exploration phase
        ae, encoder, decoder = create_auto_encoder(model_type=auto_encoder_3d,
                                                   phase=phase,
                                                   population=np.asarray(training_population),
                                                   noisy=None)

        # Save the novel population to a numpy file and clear the python list
        np.save("./Delenox_Experiment_Data/Phase{:d}/Training_Set.npy".format(phase), np.asarray(training_population))
        training_population.clear()

        # Clear the plotting library's cache to make sure we aren't wasting memory
        plt.close('all')
